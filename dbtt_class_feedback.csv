What did you learn in this week's session that you find most useful?,"What do you like best in this session? For example, which topic is interesting, activity that you enjoyed?","What is most challenging in this week's session? Please provide constructive feedback to improve the session. For example, is there any topic that you need additional explanation?",Any other thoughts or comments on this week's coverage.,How many times have you participated in the session today? Briefly describe them.,Please rate your understanding of this session.,This class session enhanced my understanding of the material. (1-7),This class session facilitated my learning. (1-7),My level of learning in this session was high. (1-7),Overall experience for the class. (1-10)
Understanding the difference between algorithm and model clarified a lot for me.,I enjoyed the practical session on building a classifier.,The concept of F1-score was a bit confusing initially.,Looking forward to more hands-on examples.,I raised a point during the confusion matrix example.,Strongly Agree - understand almost fully,6,5,7,10
The difference between algorithms and models,The session on evaluating models was the most engaging part.,Differentiating between precision and recall was slightly challenging.,I like how the class integrates theory with practice.,I was active in the breakout session and shared my screen.,Strongly Agree - understand almost fully,5,6,7,8
"I found the cloud computing overview helpful, though I think I need more practice.",The hands-on data preparation activity helped solidify my understanding.,The explanation of classification metrics needs more examples.,"No further comments, great session!",I asked a question during the precision vs recall discussion and participated in the breakout activity.,Agree - Understand quite a lot,6,5,5,9
The confusion matrix was a new but useful concept.,Clear explanations of the differences between Generative and Non-Generative AI,I would appreciate slower pacing during the model evaluation section.,The pace was just right this week.,I answered one poll and worked in the breakout room.,Agree - Understand quite a lot,6,7,5,9
When to use different classification algorithms,The example on fraud detection and recall vs precision trade-off was interesting.,I think more time could be spent on explaining when to use each algorithm.,It would help to have the slides earlier.,"I contributed twice, once in chat and once during group work.",Agree - Understand quite a lot,7,6,7,8
I now know how to evaluate models using F1-score.,I liked the visual explanation of classification vs regression.,I found the distinction between recall and precision a bit subtleâ maybe another example would help.,Thanks for the sessionâ looking forward to more practice-based learning!,I participated during the classifier-building exercise and answered one question in the chat.,Agree - Understand quite a lot,7,6,6,8
I found the explanation of precision and recall most useful.,I liked the interactive activity where we worked with a small dataset to build a classifier.,Understanding the F1-score math was tough without a calculator. Maybe a visual could help.,"Great coverage overall, perhaps a mini quiz at the end would help retention.",I helped my group interpret the confusion matrix during the activity.,Strongly Agree - understand almost fully,7,6,7,10
The trade-off between precision and recall,I really enjoyed the breakdown of how the F1-score balances precision and recall Ñ it felt like a useful summary metric I can actually apply.,I struggled slightly with applying the theory to the classifier building practical.,Enjoyed todayâ€™s class. Having short recaps between sections is really effective.,I asked a clarification question during the recap on F1-score.,Agree - Understand quite a lot,5,5,5,9
How to evaluate model performance using metrics like F1-score,I appreciated the visualisation of model evaluation through diagramsâ made abstract ideas tangible.,The section on classification metrics felt rushed. Slowing down or using polling could help check understanding.,I think we had a good mix of theory and practical this time. Keep it up!,"I participated twiceâ once during the breakout, once while reviewing evaluation metrics.",Agree - Understand quite a lot,5,6,5,8
Understanding Confusion Matrix,The instructor's way of comparing precision vs recall with real-life analogies was engaging.,Some of the examples assumed prior stats knowledgeâmaybe a glossary would help for key terms.,All goodâcontent was rich and clear today. Appreciate the live examples.,I responded to a peer's observation in the discussion and was part of the breakout analysis. ,Agree - Understand quite a lot,5,7,6,9
The limitations of Generative AI for structured data,The recap slides before the exercise were helpful in reinforcing concepts from earlier sessions. ,Choosing the right algorithm for a specific problem,A deeper dive into the concept of bias in model evaluation.,Participated in the class discussion,Strongly Agree - understand almost fully,5,7,5,9
I found the explanation of precision and recall really clarified how we evaluate model performance.,I liked the interactive activity where we worked with a small dataset to build a classifier. ,Understanding the mathematical formulas behind the evaluation metrics,More examples on applying different classification algorithms,Asked questions during the lecture,Strongly Agree - understand almost fully,5,7,7,9
Understanding the trade-offs in evaluation metrics like F1-score helped me realise accuracy isn't everything.,The examples about spam detection and fraud risk were very relevant and made concepts stick. ,Applying the concepts to real-world datasets.,More clarification on the use cases of Generative AI vs. Non-Generative AI,Contributed to group activity,Strongly Agree - understand almost fully,7,6,5,9
"Learning about confusion matrices was useful, especially seeing how false positives and negatives impact real decisions.",The practical demo using confusion matrix examples helped me visualise how classification errors occur in real models.,Distinguishing between different types of classification algorithms,"Explanation of the difference between True Positive, True Negative, False Positive and False Negative",Answered questions asked by the lecturer,Strongly Agree - understand almost fully,7,7,7,9
The discussion on the difference between algorithm and model gave me a clearer picture of machine learning workflows.,Hands-on exercises on calculating evaluation metrics.,"Grasping the nuances of precision, recall, and F1-score",NA,"I participated twice Ñ once by answering a question about precision vs recall, and once during the group discussion when we analysed the confusion matrix",Strongly Agree - understand almost fully,5,5,6,9
The walkthrough of classification vs regression made it easier to categorise problems appropriately. ,The visual algorithm cheat sheet,NIL,NA,I answered a poll question at the start and later typed a response in the chat during the model evaluation activity.,Strongly Agree - understand almost fully,7,7,6,7
I found the explanation of precision and recall really clarified how we evaluate model performance. ,The practical examples of when to prioritise precision or recall,NIL,NA,I helped my group present our classifier findings and asked a follow-up question about accuracy during the wrap-up.,Strongly Agree - understand almost fully,7,6,6,9
Understanding the trade-offs in evaluation metrics like F1-score helped me realise accuracy isn't everything. ,The discussion on the ethical implications of model misclassification,I found the explanation of the F1-score a bit abstract at first Ñ a step-by-step breakdown using actual values from a confusion matrix would have helped solidify it.,NA,I contributed once during the breakout activity and once again when we discussed the trade-offs between false positives and false negatives.,Agree - Understand quite a lot,6,5,5,10
I learned how misleading a high accuracy score can be when dealing with imbalanced datasets,I liked the discussion on real-world cases like fraud detection and how model evaluation needs to adapt depending on business impact,NIL,NA,N/A,Strongly Agree - understand almost fully,7,6,7,8